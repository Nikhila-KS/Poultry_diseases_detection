{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c2e6fc4-162f-466f-a61f-5b68a7d8ce11",
   "metadata": {},
   "source": [
    "# MobileNetV2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6e02f3-0a64-4079-acf5-f2a26ade80b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "\n",
    "# Open file\n",
    "import os\n",
    "import PIL\n",
    "from random import seed\n",
    "# Model CNN (Deep learning network)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense,\\\n",
    "GlobalAveragePooling2D, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa822d6-3c05-43e0-92d2-0195dca1e952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function plot loss function and accuracy score graph\n",
    "def plot_graph(model_values):\n",
    "    ''' \n",
    "    Input : Model_values of keras.callbacks.History\n",
    "    Return : Graph of Loss function and accuracy score between training dataset and vaildation dataset\n",
    "    '''\n",
    "    # Subplots\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14,5))\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(model_values.history['loss'], label='Training Loss');\n",
    "    plt.plot(model_values.history['val_loss'], label='Testing Loss');\n",
    "    plt.legend(fontsize=12, loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss');\n",
    "    \n",
    "    # Plot MSE\n",
    "    plt.subplot(1, 2, 2)\n",
    "    \n",
    "    plt.plot(model_values.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(model_values.history['val_accuracy'], label='Validation Accuracy')\n",
    "    \n",
    "    plt.legend(fontsize=12, loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da573690-0ac7-49c2-9a36-81ddc8c1ac89",
   "metadata": {},
   "source": [
    "## 00- First check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328d7947-fc13-4c69-b904-ff6ee1588d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/guide/keras/sequential_model\n",
    "# Due to we use Keras Sequential API, \n",
    "# We want to check GPU first before training our model for \n",
    "# impore efficiency and reduce time. \n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4cd37e-1d40-446a-a23a-7048ede520e8",
   "metadata": {},
   "source": [
    "## 01- Open dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c44add-8de3-4f60-9f26-0815c69c2bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths\n",
    "original_dataset_path = r'C:\\Users\\HP\\Desktop\\Data\\poultry_disease_detection_third_iteration\\poultry_data'\n",
    "train_path = r\"C:\\Users\\HP\\Desktop\\Data\\poultry_disease_detection_third_iteration\\Train\"\n",
    "validation_path = r\"C:\\Users\\HP\\Desktop\\Data\\poultry_disease_detection_third_iteration\\Validate\"\n",
    "test_path = r\"C:\\Users\\HP\\Desktop\\Data\\poultry_disease_detection_third_iteration\\Test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ee7062-96b4-4e85-ae08-91dcda63c3f1",
   "metadata": {},
   "source": [
    "## 02 Preprocessing image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f6c62b-a740-4860-ad51-9718b5f357f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter of image \n",
    "# https://github.com/keras-team/keras/issues/8090#issuecomment-335155737\n",
    "batch_size = 50 # Set the batch size for epoch cycle\n",
    "img_height = 128 # Set the height of the picture\n",
    "img_width = 128 # Set the width of the picture\n",
    "\n",
    "# Rescale pixel to reduce image size before using in model\n",
    "data_gen_train = ImageDataGenerator(rescale=1/255.)\n",
    "data_gen_valid = ImageDataGenerator(rescale=1/255.)\n",
    "data_gen_test = ImageDataGenerator(rescale=1/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61de4a33-fe75-4b77-a5a4-5ff9dedead1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training dataset\n",
    "train_dataset = data_gen_train.flow_from_directory(train_path,\n",
    "                                                   class_mode=\"categorical\",\n",
    "                                                   target_size=(img_height, img_width),\n",
    "                                                   batch_size=batch_size)\n",
    "\n",
    "# Create validation dataset\n",
    "valid_dataset = data_gen_valid.flow_from_directory(validation_path,\n",
    "                                                   class_mode=\"categorical\",\n",
    "                                                   target_size=(img_height, img_width),\n",
    "                                                   batch_size=batch_size)\n",
    "\n",
    "# Create testing dataset\n",
    "test_dataset = data_gen_test.flow_from_directory(test_path,\n",
    "                                                 class_mode=\"categorical\",\n",
    "                                                 target_size=(img_height, img_width),\n",
    "                                                 batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d259a50c-027f-44fa-9738-e852fcbcdf11",
   "metadata": {},
   "source": [
    "## 03 MobileNetV2 model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856be21f-4c68-4806-b006-d6d63220b069",
   "metadata": {},
   "source": [
    "### Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e3d224-7389-4062-aed9-37f65d333672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/api/applications/mobilenet/#mobilenetv2-function\n",
    "# import MobileNetV2 model form keras API\n",
    "# set input size of image of trianing is 128x128 (smallest size of MobileNetV2)\n",
    "# due to we want to use transfer learning process \n",
    "# we must add `include_top=False` because we wan to add our input data \n",
    "# we decide default weigh for mode\n",
    "mobv2_model = tf.keras.applications.MobileNetV2(input_shape=(128,128,3),\n",
    "                                                include_top=False, # Transfer learning\n",
    "                                                weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39909ce2-1c34-4ee9-be25-3b51ef378b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model summary\n",
    "# Total params: 2,257,984\n",
    "# Trainable params: 2,223,872\n",
    "# Non-trainable params: 34,112\n",
    "mobv2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4619cf9e-5030-458c-baec-124a596c386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix weights and bias \n",
    "# train specifically custom head\n",
    "mobv2_model.trainable=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ff1328-e210-4af3-be4f-2703d445a86f",
   "metadata": {},
   "source": [
    "### Add custom head and output layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b791830a-fd59-449a-bf98-796d7356cf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output layer \n",
    "# We have 4 classes in our output we decide using activation=\"softmax\" \n",
    "# for multi classification.\n",
    "# Before output layer we decide use GlobalAveragePooling2D as \n",
    "# one type of flatten layer.\n",
    "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(mobv2_model.output) # flatten\n",
    "prediction_layer = tf.keras.layers.Dense(units=4, activation=\"softmax\")(average_pooling_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaccfb6-66f1-433c-b7f4-292631801021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Input layer and output layer \n",
    "model = tf.keras.models.Model(inputs=mobv2_model.input, \n",
    "                                    outputs=prediction_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af600a91-345a-435d-8871-a8a4734aec4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total params: 2,263,108\n",
    "# Trainable params: 5,124 # add input layers and  output layers\n",
    "# Non-trainable params: 2,257,984 --> fix layers\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997d5d5a-b082-40b6-a72f-d0bf3793535f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model         \n",
    "model.compile(loss=\"categorical_crossentropy\", \n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a1eadb-f833-4b25-a308-698adcc987ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save checkpoints during training\n",
    "checkpoint_path = r'C:\\Users\\HP\\Desktop\\Data\\poultry_disease_detection_third_iteration\\models\\mobilenetv2\\mobilenetv2_cp\\cp.ckpt'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 mode=\"max\",\n",
    "                                                 verbose=1,\n",
    "                                                 monitor=\"val_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f99e60-3c5f-4f68-826b-f3cf1e867489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model\n",
    "# make sure you truely save checkpoint_path\n",
    "history = model.fit(train_dataset,\n",
    "          epochs=25,\n",
    "          validation_data=valid_dataset,\n",
    "          callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e375c64-8e59-4d43-834e-e20951a7c9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot graph \n",
    "plot_graph(history)\n",
    "\n",
    "\n",
    "# overfitting between training and validation \n",
    "# Final accuracy after training 25 epochs is score in training 0.98% \n",
    "# and vaildaion 0.90%\n",
    "# Loss function after training 25 epochs is score in training 0.06% \n",
    "# and vaildaion 0.31%\n",
    "# Goof perfomance than baseline model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78edc32-e546-4463-8176-8047a2cc6a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save(r\"C:\\Users\\HP\\Desktop\\Data\\poultry_disease_detection_third_iteration\\models\\mobilenetv2\\mobilenetv2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2232a26-9b40-47b5-ac06-30d1d0e1bb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the history.history dict to a pandas DataFrame:    \n",
    "hist_df = pd.DataFrame(history.history) \n",
    "# # save history to csv:  \n",
    "# hist_csv_file = r\"C:\\Users\\HP\\Desktop\\Data\\poultry_new\\model\\mobilenetV2\\history_mobilenetv2_tf.csv\"\n",
    "# with open(hist_csv_file, mode='w') as f:\n",
    "#     hist_df.to_csv(f)\n",
    "\n",
    "# Save history to CSV file\n",
    "hist_csv_file = r\"C:\\Users\\HP\\Desktop\\Data\\poultry_disease_detection_third_iteration\\models\\mobilenetv2\\history_mobilenetv2_tl.csv\"\n",
    "hist_df.to_csv(hist_csv_file, index=False)  # Set index=False to exclude the index column\n",
    "\n",
    "hist_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9099afc6-8bd5-4612-94ea-40e6d0c05623",
   "metadata": {},
   "source": [
    "### Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a12f2a-0be7-4f54-9a8f-1ff8daecf756",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 128 # Set the height of the picture\n",
    "img_width = 128 # Set the width of the picture\n",
    "\n",
    "# load model\n",
    "mobv2_model = tf.keras.applications.MobileNetV2(input_shape=(img_height, img_width,3),\n",
    "                                              include_top=False, # Transfer learning\n",
    "                                              weights=\"imagenet\",\n",
    "                                              )  \n",
    "\n",
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(mobv2_model.layers))\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 100\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in mobv2_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Make sure you have frozen the correct layers\n",
    "for i, layer in enumerate(mobv2_model.layers):\n",
    "    if i >= 95:\n",
    "        print(i, layer.name, layer.trainable)\n",
    "\n",
    "# Add input layers and output layers\n",
    "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(mobv2_model.output) # flatten\n",
    "prediction_layer = tf.keras.layers.Dense(units=4, activation=\"softmax\")(average_pooling_layer)\n",
    "fineture_model = tf.keras.models.Model(inputs=mobv2_model.input, \n",
    "                                     outputs=prediction_layer)\n",
    "\n",
    "# Compile the model         \n",
    "fineture_model.compile(loss=\"categorical_crossentropy\", \n",
    "                       optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                       metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adbd4be-569b-4253-96f8-6a47bcbcb5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save checkpoints during training\n",
    "# follow value of vaildation scorce \n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(r'C:\\Users\\HP\\Desktop\\Data\\poultry_disease_detection_third_iteration\\models\\mobilenetv2\\ft_cp\\mobilenetv2_ft.h5', \n",
    "                             monitor= 'val_accuracy', \n",
    "                             mode= 'max', \n",
    "                             save_best_only = True, \n",
    "                             verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4230d8a8-ce6b-4c18-9f3f-0eef34fa530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model\n",
    "# make sure you truely save checkpoint_path\n",
    "history_ft = fineture_model.fit(train_dataset,  \n",
    "                             epochs=25, \n",
    "                             validation_data=valid_dataset, \n",
    "                             callbacks=[checkpoint]) # fine tune continue form transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9763caf5-f519-472e-92fe-b0da50f33b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot graph \n",
    "plot_graph(history_ft)\n",
    "\n",
    "# Slightly Overfitting between training and validation \n",
    "# Final accuracy after fine tuning 25 epochs is up score in training 1.00% (at 23 epoch) \n",
    "# and vaildaion 0.93% (better than transfer learning)\n",
    "# Loss function after training 25 epochs is down score in training 0.01%  (at 23 epoch)\n",
    "# and vaildaion 0.78% (worse than transfer learning)\n",
    "# Higher perfomance than baseline model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472338e3-709a-41b3-bbdb-04e0db1c0443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model after fine tuning\n",
    "fineture_model.save(r\"C:\\Users\\HP\\Desktop\\Data\\poultry_disease_detection_third_iteration\\models\\mobilenetv2\\mobilenetv2_ft.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5764a2-ffe9-4a27-b9dd-705842940a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the history.history dict to a pandas DataFrame:     \n",
    "hist_df = pd.DataFrame(history_ft.history) \n",
    "\n",
    "# # save to csv: \n",
    "# hist_csv_file = '../model/mobilenetV2/history_mobilenetv2_ft.csv'\n",
    "# with open(hist_csv_file, mode='w') as f:\n",
    "#     hist_df.to_csv(f)\n",
    "\n",
    "# Save history to CSV file\n",
    "hist_csv_file = r\"C:\\Users\\HP\\Desktop\\Data\\poultry_disease_detection_third_iteration\\models\\mobilenetv2\\history_mobilenetv2_ft.csv\"\n",
    "hist_df.to_csv(hist_csv_file, index=False)  # Set index=False to exclude the index column\n",
    "\n",
    "hist_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36abf8c3-4467-4be5-9fb4-a8dbce585c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c5fbb6-f75e-4c92-8695-9e370f8ae508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
